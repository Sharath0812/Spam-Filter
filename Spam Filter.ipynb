{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Python\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "G:\\Python\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\M.Sharath\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[[127  31]\n",
      " [112 845]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.80      0.64       158\n",
      "          1       0.96      0.88      0.92       957\n",
      "\n",
      "avg / total       0.90      0.87      0.88      1115\n",
      "\n",
      "[[117  41]\n",
      " [  0 957]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.74      0.85       158\n",
      "          1       0.96      1.00      0.98       957\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "dataset = pd.read_csv('spam.csv',encoding='latin-1')\n",
    "dataset.head()\n",
    "dataset = dataset.drop(['Unnamed: 2' , 'Unnamed: 3', 'Unnamed: 4'],axis=1)\n",
    "dataset.head()\n",
    "dataset = dataset.rename(columns={'v1':'Target','v2':'SMS'})\n",
    "nltk.download('stopwords')\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(len(dataset['SMS'])):\n",
    " clean_sms = re.sub('[^a-zA-Z]',' ',dataset['SMS'][i])\n",
    " clean_sms = clean_sms.lower()\n",
    " clean_sms = clean_sms.split()\n",
    " clean_sms = [ps.stem(word) for word in clean_sms if not word in set(stopwords.words('english'))]\n",
    " clean_sms = ' '.join(clean_sms)\n",
    " corpus.append(clean_sms)\n",
    "corpus\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X\n",
    "y = dataset.iloc[:,0].values\n",
    "y\n",
    "for i in range(len(y)):\n",
    "    if y[i] == 'ham':\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "y = y.astype(np.int64)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 2)\n",
    "gb = GaussianNB()\n",
    "gb.fit(X_train,y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "cn = confusion_matrix(y_test,y_pred)\n",
    "print(cn)\n",
    "print(classification_report(y_test,y_pred))\n",
    "rf = RandomForestClassifier(n_estimators = 200)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred2 = rf.predict(X_test)\n",
    "cn2 = confusion_matrix(y_test,y_pred2)\n",
    "print(cn2)\n",
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
